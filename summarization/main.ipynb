{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"03230fb27ddf4eef957d52feadb0b89b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f4905b921c1491cadae2b9c12225039":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_93682f2ea2624c20a290e049a0a9a7a6","IPY_MODEL_ee01a36eb33547ed93c4a0151fad34dc","IPY_MODEL_c80a3a213dcb472d97853828dc98b3ef"],"layout":"IPY_MODEL_81965205ebf64cd7aacdf3a76cecb6a0"}},"22c09ca25d2140f0a57f5794e365dd15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"333d95d0522943a1a626497184d1a347":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"645d7a349cbe4ca4859f4e014fa0e6a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81965205ebf64cd7aacdf3a76cecb6a0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ebb544dcaf845b6ad10311f475a6792":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93682f2ea2624c20a290e049a0a9a7a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03230fb27ddf4eef957d52feadb0b89b","placeholder":"​","style":"IPY_MODEL_22c09ca25d2140f0a57f5794e365dd15","value":"Loading checkpoint shards: 100%"}},"ba3240daf67d45ca886b836c67a3fbf0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c80a3a213dcb472d97853828dc98b3ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba3240daf67d45ca886b836c67a3fbf0","placeholder":"​","style":"IPY_MODEL_645d7a349cbe4ca4859f4e014fa0e6a9","value":" 2/2 [00:20&lt;00:00,  9.04s/it]"}},"ee01a36eb33547ed93c4a0151fad34dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ebb544dcaf845b6ad10311f475a6792","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_333d95d0522943a1a626497184d1a347","value":2}}}},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Introduction","metadata":{}},{"cell_type":"code","source":"!pip install datasets trl bitsandbytes accelerate rouge_score evaluate","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-05-12T22:20:26.954005Z","iopub.execute_input":"2025-05-12T22:20:26.954674Z","iopub.status.idle":"2025-05-12T22:22:03.358862Z","shell.execute_reply.started":"2025-05-12T22:20:26.954651Z","shell.execute_reply":"2025-05-12T22:22:03.358125Z"},"id":"MVd13x8IPm8B","outputId":"9d4bf7f8-fe3c-47cd-e68b-4b22ea1c63c2","trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nCollecting trl\n  Downloading trl-0.17.0-py3-none-any.whl.metadata (12 kB)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (14.0.0)\nRequirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.51.1)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.2)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (0.21.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading trl-0.17.0-py3-none-any.whl (348 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.0/348.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=6587f2df4d8b739a42cfa14a64ebea65a7e6761c207fb7d4044e535a6f3dac6c\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge_score\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, trl, rouge_score, evaluate, bitsandbytes\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.5 evaluate-0.4.3 fsspec-2024.12.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rouge_score-0.1.2 trl-0.17.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    AutoTokenizer,\n    TrainingArguments,\n    Trainer,\n    GenerationConfig,\n    set_seed\n)\nfrom tqdm import tqdm\nfrom trl import SFTTrainer\nimport torch\nimport time\nimport pandas as pd\nimport numpy as np\nimport os\nimport random\nfrom pynvml import *\nfrom functools import partial","metadata":{"execution":{"iopub.status.busy":"2025-05-12T22:22:03.360457Z","iopub.execute_input":"2025-05-12T22:22:03.360745Z","iopub.status.idle":"2025-05-12T22:22:32.365850Z","shell.execute_reply.started":"2025-05-12T22:22:03.360717Z","shell.execute_reply":"2025-05-12T22:22:32.365243Z"},"id":"DmFrYP6LPkEv","trusted":true},"outputs":[{"name":"stderr","text":"2025-05-12 22:22:16.830369: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747088537.021653      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747088537.073431      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"os.environ['WANDB_DISABLED']=\"true\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:22:32.366666Z","iopub.execute_input":"2025-05-12T22:22:32.366922Z","iopub.status.idle":"2025-05-12T22:22:32.370767Z","shell.execute_reply.started":"2025-05-12T22:22:32.366898Z","shell.execute_reply":"2025-05-12T22:22:32.370071Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"GLOBAL_SEED = 42\n\nrandom.seed(GLOBAL_SEED)\n\nnp.random.seed(GLOBAL_SEED)\n\ntorch.manual_seed(GLOBAL_SEED)\ntorch.cuda.manual_seed_all(GLOBAL_SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nset_seed(GLOBAL_SEED)\n\nprint(f\"All random seeds have been set to {GLOBAL_SEED} for reproducibility.\")","metadata":{"execution":{"iopub.status.busy":"2025-05-12T22:22:32.372823Z","iopub.execute_input":"2025-05-12T22:22:32.373102Z","iopub.status.idle":"2025-05-12T22:22:32.434205Z","shell.execute_reply.started":"2025-05-12T22:22:32.373084Z","shell.execute_reply":"2025-05-12T22:22:32.433612Z"},"trusted":true},"outputs":[{"name":"stdout","text":"All random seeds have been set to 42 for reproducibility.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Dataset preparation","metadata":{}},{"cell_type":"code","source":"huggingface_dataset_name = \"abisee/cnn_dailymail\"\ndataset = load_dataset(huggingface_dataset_name, \"3.0.0\") \ndataset","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-05-12T22:22:32.435114Z","iopub.execute_input":"2025-05-12T22:22:32.435430Z","iopub.status.idle":"2025-05-12T22:22:43.334685Z","shell.execute_reply.started":"2025-05-12T22:22:32.435403Z","shell.execute_reply":"2025-05-12T22:22:43.334057Z"},"id":"ldFhRMQcQQuH","outputId":"62bc3383-a368-4506-e1d1-d7d86ba4bf9f","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dee045806a541908c3b1f7aac509bc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3e497bec7ab41bebd1d5e39622c6005"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07ccac33f8114f3eb9c0ddac7fb5edde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00002-of-00003.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"389f578b668a420fb8e7b1d8f788f724"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/34.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38457ddca79c4514a4ddecdefd9be7f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/30.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6c6f907e0124158be6471a19702277c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9476b65559f4c9483638aa3fabc0d05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a69f09a077744874a95beae8f47b8de8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b9d9ce0909e44c29a3348067f8802b4"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 287113\n    })\n    validation: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 13368\n    })\n    test: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 11490\n    })\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"dataset['train'][0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-05-12T22:22:43.335428Z","iopub.execute_input":"2025-05-12T22:22:43.335670Z","iopub.status.idle":"2025-05-12T22:22:43.340762Z","shell.execute_reply.started":"2025-05-12T22:22:43.335640Z","shell.execute_reply":"2025-05-12T22:22:43.340130Z"},"id":"c78xfmCNQYey","outputId":"46982e88-71d6-46e9-8712-f501dbd9c776","trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'article': 'LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.',\n 'highlights': \"Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\\nYoung actor says he has no plans to fritter his cash away .\\nRadcliffe's earnings from first five Potter films have been held in trust fund .\",\n 'id': '42c027e4ff9730fbb3de84c1af0d2c506e41c3e4'}"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"combined_dataset = {\n    'train': dataset['train'],\n    'validation': dataset['validation'],\n    'test': dataset['test']\n}\n\ntrain_size = len(combined_dataset['train'])\nvalidation_size = len(combined_dataset['validation'])\ntest_size = len(combined_dataset['test'])\ntotal_size = train_size + validation_size + test_size\n\nprint(f\"Total dataset size: {total_size}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:22:43.341454Z","iopub.execute_input":"2025-05-12T22:22:43.341704Z","iopub.status.idle":"2025-05-12T22:22:43.355615Z","shell.execute_reply.started":"2025-05-12T22:22:43.341680Z","shell.execute_reply":"2025-05-12T22:22:43.354850Z"}},"outputs":[{"name":"stdout","text":"Total dataset size: 311971\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"new_train_size = int(0.70 * total_size)\nnew_val_size = int(0.15 * total_size)\nnew_dev_size = int(0.10 * total_size)\nnew_test_size = int(0.05 * total_size)\n\nprint(f\"New train size: {new_train_size}\")\nprint(f\"New validation size: {new_val_size}\")\nprint(f\"New dev size: {new_dev_size}\")\nprint(f\"New test size: {new_test_size}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:22:43.356358Z","iopub.execute_input":"2025-05-12T22:22:43.356688Z","iopub.status.idle":"2025-05-12T22:22:43.369802Z","shell.execute_reply.started":"2025-05-12T22:22:43.356661Z","shell.execute_reply":"2025-05-12T22:22:43.369094Z"}},"outputs":[{"name":"stdout","text":"New train size: 218379\nNew validation size: 46795\nNew dev size: 31197\nNew test size: 15598\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from datasets import concatenate_datasets\n\nall_data = concatenate_datasets([\n    dataset['train'],\n    dataset['validation'],\n    dataset['test']\n])\n\nshuffled_indices = np.random.permutation(len(all_data))\nall_data = all_data.select(shuffled_indices)\n\nnew_train_size = int(0.70 * len(all_data))\nnew_val_size = int(0.15 * len(all_data))\nnew_dev_size = int(0.10 * len(all_data))\nnew_test_size = int(0.05 * len(all_data))\n\nnew_train_dataset = all_data.select(range(0, new_train_size))\nnew_val_dataset = all_data.select(range(new_train_size, new_train_size + new_val_size))\nnew_dev_dataset = all_data.select(range(new_train_size + new_val_size, new_train_size + new_val_size + new_dev_size))\nnew_test_dataset = all_data.select(range(new_train_size + new_val_size + new_dev_size, new_train_size + new_val_size + new_dev_size + new_test_size))\n\nprint(f\"New train dataset size: {len(new_train_dataset)}\")\nprint(f\"New validation dataset size: {len(new_val_dataset)}\")\nprint(f\"New dev dataset size: {len(new_dev_dataset)}\")\nprint(f\"New test dataset size: {len(new_test_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:22:43.370551Z","iopub.execute_input":"2025-05-12T22:22:43.370832Z","iopub.status.idle":"2025-05-12T22:22:43.479684Z","shell.execute_reply.started":"2025-05-12T22:22:43.370815Z","shell.execute_reply":"2025-05-12T22:22:43.479049Z"}},"outputs":[{"name":"stdout","text":"New train dataset size: 218379\nNew validation dataset size: 46795\nNew dev dataset size: 31197\nNew test dataset size: 15598\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Model preparation","metadata":{}},{"cell_type":"markdown","source":"Quantization to load large model more efficiently","metadata":{}},{"cell_type":"code","source":"compute_dtype = getattr(torch, \"float16\")\nbnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type='nf4',\n        bnb_4bit_compute_dtype=compute_dtype,\n        bnb_4bit_use_double_quant=False,\n    )\ndevice_map = {\"\": 0}","metadata":{"execution":{"iopub.status.busy":"2025-05-12T22:22:43.481842Z","iopub.execute_input":"2025-05-12T22:22:43.482116Z","iopub.status.idle":"2025-05-12T22:22:43.486883Z","shell.execute_reply.started":"2025-05-12T22:22:43.482100Z","shell.execute_reply":"2025-05-12T22:22:43.486335Z"},"id":"OExNdyBfQbuR","trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model_name='microsoft/phi-2'\noriginal_model = AutoModelForCausalLM.from_pretrained(model_name,\n                                                      device_map=device_map,\n                                                      quantization_config=bnb_config,\n                                                      trust_remote_code=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["0f4905b921c1491cadae2b9c12225039","93682f2ea2624c20a290e049a0a9a7a6","ee01a36eb33547ed93c4a0151fad34dc","c80a3a213dcb472d97853828dc98b3ef","81965205ebf64cd7aacdf3a76cecb6a0","03230fb27ddf4eef957d52feadb0b89b","22c09ca25d2140f0a57f5794e365dd15","8ebb544dcaf845b6ad10311f475a6792","333d95d0522943a1a626497184d1a347","ba3240daf67d45ca886b836c67a3fbf0","645d7a349cbe4ca4859f4e014fa0e6a9"]},"execution":{"iopub.status.busy":"2025-05-12T22:22:43.487462Z","iopub.execute_input":"2025-05-12T22:22:43.487636Z","iopub.status.idle":"2025-05-12T22:23:14.736984Z","shell.execute_reply.started":"2025-05-12T22:22:43.487622Z","shell.execute_reply":"2025-05-12T22:23:14.736103Z"},"id":"rNi14jQjQ4b5","outputId":"2c32021b-d4a1-4324-8a4b-185151366b76","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"302453007c6045e0953cce3a011eecf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c476a0c98e341dfb200096554cb4025"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea61c6d368a34607ba268ae195dec62c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7620fddee5c6433ca4d30243488d0224"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07010823b5524059bafa37714825bc71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a9ead2cacf446a8adfa97728890951a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03ac5d9bcd694ec2a18f924f30d9862a"}},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"Tokenize dataset","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code=True,padding_side=\"left\",add_eos_token=True,add_bos_token=True,use_fast=False)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2025-05-12T22:23:14.737885Z","iopub.execute_input":"2025-05-12T22:23:14.738163Z","iopub.status.idle":"2025-05-12T22:23:16.685153Z","shell.execute_reply.started":"2025-05-12T22:23:14.738139Z","shell.execute_reply":"2025-05-12T22:23:16.684346Z"},"id":"6_IZxFLUSCUg","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5b780f73da948fb987fc11a52d7abc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77a477220c70400687bc82d274a77e35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f56fe6113ed94c96b9363870cbc6b413"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00e5cacf8a284d04a3344d77c9bf8107"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a81ef67de0b483e900a4a064ad1b2aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b28b89c9dd834e229a885251dbc74051"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"eval_tokenizer = AutoTokenizer.from_pretrained(model_name, add_bos_token=True, trust_remote_code=True, use_fast=False)\neval_tokenizer.pad_token = eval_tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:23:16.687105Z","iopub.execute_input":"2025-05-12T22:23:16.687396Z","iopub.status.idle":"2025-05-12T22:23:17.484166Z","shell.execute_reply.started":"2025-05-12T22:23:16.687365Z","shell.execute_reply":"2025-05-12T22:23:17.483341Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def create_prompt_formats(sample):\n    \"\"\"\n    Format various fields of the sample ('instruction','output')\n    Then concatenate them using two newline characters\n    :param sample: Sample dictionary\n    \"\"\"\n    INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n    INSTRUCTION_KEY = \"### Instruct: Summarize the below article.\"\n    RESPONSE_KEY = \"### Output:\"\n    END_KEY = \"### End\"\n\n    blurb = f\"\\n{INTRO_BLURB}\"\n    instruction = f\"{INSTRUCTION_KEY}\"\n    input_context = f\"{sample['article']}\" if sample[\"article\"] else None\n    response = f\"{RESPONSE_KEY}\\n{sample['highlights']}\"\n    end = f\"{END_KEY}\"\n\n    parts = [part for part in [blurb, instruction, input_context, response, end] if part]\n\n    formatted_prompt = \"\\n\\n\".join(parts)\n    sample[\"text\"] = formatted_prompt\n\n    return sample","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:23:17.484969Z","iopub.execute_input":"2025-05-12T22:23:17.485171Z","iopub.status.idle":"2025-05-12T22:23:18.460562Z","shell.execute_reply.started":"2025-05-12T22:23:17.485149Z","shell.execute_reply":"2025-05-12T22:23:18.459622Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def preprocess_batch(batch, tokenizer, max_length):\n    return tokenizer(\n        batch[\"text\"],\n        max_length=max_length,\n        truncation=True,\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:23:18.461635Z","iopub.execute_input":"2025-05-12T22:23:18.461926Z","iopub.status.idle":"2025-05-12T22:23:18.890009Z","shell.execute_reply.started":"2025-05-12T22:23:18.461901Z","shell.execute_reply":"2025-05-12T22:23:18.889280Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def preprocess_dataset(tokenizer: AutoTokenizer, max_length: int, seed, dataset):\n    \"\"\"Format & tokenize it so it is ready for training\n    :param tokenizer (AutoTokenizer): Model Tokenizer\n    :param max_length (int): Maximum number of tokens to emit from tokenizer\n    \"\"\"\n\n    print(\"Preprocessing dataset...\")\n    dataset = dataset.map(create_prompt_formats)\n\n    _preprocessing_function = partial(preprocess_batch, max_length=max_length, tokenizer=tokenizer)\n    dataset = dataset.map(\n        _preprocessing_function,\n        batched=True,\n        remove_columns=['id', 'article', 'highlights'],  # Updated column names\n    )\n\n    dataset = dataset.filter(lambda sample: len(sample[\"input_ids\"]) < max_length)\n\n    dataset = dataset.shuffle(seed=seed)\n\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:23:18.890882Z","iopub.execute_input":"2025-05-12T22:23:18.891156Z","iopub.status.idle":"2025-05-12T22:23:18.900925Z","shell.execute_reply.started":"2025-05-12T22:23:18.891132Z","shell.execute_reply":"2025-05-12T22:23:18.900346Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def get_max_length(model):\n    conf = model.config\n    max_length = None\n    for length_setting in [\"n_positions\", \"max_position_embeddings\", \"seq_length\"]:\n        max_length = getattr(model.config, length_setting, None)\n        if max_length:\n            print(f\"Found max lenth: {max_length}\")\n            break\n    if not max_length:\n        max_length = 1024\n        print(f\"Using default max length: {max_length}\")\n    return max_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:23:18.901836Z","iopub.execute_input":"2025-05-12T22:23:18.902079Z","iopub.status.idle":"2025-05-12T22:23:18.915014Z","shell.execute_reply.started":"2025-05-12T22:23:18.902055Z","shell.execute_reply":"2025-05-12T22:23:18.914440Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"max_length = get_max_length(original_model)\nprint(f\"Using max length: {max_length}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:23:18.915766Z","iopub.execute_input":"2025-05-12T22:23:18.916039Z","iopub.status.idle":"2025-05-12T22:23:18.932861Z","shell.execute_reply.started":"2025-05-12T22:23:18.916017Z","shell.execute_reply":"2025-05-12T22:23:18.932303Z"}},"outputs":[{"name":"stdout","text":"Found max lenth: 2048\nUsing max length: 2048\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"train_dataset = preprocess_dataset(tokenizer, max_length, GLOBAL_SEED, new_train_dataset.select(range(210)))\neval_dataset = preprocess_dataset(tokenizer, max_length, GLOBAL_SEED, new_val_dataset.select(range(45)))\ndev_dataset = preprocess_dataset(tokenizer, max_length, GLOBAL_SEED, new_dev_dataset.select(range(30)))\ntest_dataset = preprocess_dataset(tokenizer, max_length, GLOBAL_SEED, new_test_dataset.select(range(15)))\n\nprint(f\"Shapes of the datasets:\")\nprint(f\"Training: {train_dataset.shape}\")\nprint(f\"Validation: {eval_dataset.shape}\")\nprint(f\"Dev: {dev_dataset.shape}\")\nprint(f\"Test: {test_dataset.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:23:18.933555Z","iopub.execute_input":"2025-05-12T22:23:18.933770Z","iopub.status.idle":"2025-05-12T22:23:25.279546Z","shell.execute_reply.started":"2025-05-12T22:23:18.933755Z","shell.execute_reply":"2025-05-12T22:23:25.278955Z"}},"outputs":[{"name":"stdout","text":"Preprocessing dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/210 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8d2fb296de346bc8004bbe0aed1209b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/210 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c06d55d47b06431ea609ba43360234b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/210 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"255a8eb2f1d24457b799756dd67fd11c"}},"metadata":{}},{"name":"stdout","text":"Preprocessing dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/45 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab163eadb94d410abc26eff37b4234e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/45 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c8a1df4fd404a65878f8ffd5ba44b72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/45 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bbcffd8ad8c4cb996b721a2115e2515"}},"metadata":{}},{"name":"stdout","text":"Preprocessing dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/30 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc7f918092b54a5d8ffa71c2c37ab736"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/30 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6086c43b2ad14777ad9f261965666be2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/30 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de125c362104400e8b0ff18a9b358c93"}},"metadata":{}},{"name":"stdout","text":"Preprocessing dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3ff3fa8154d485ea3ba0d49c1ba685b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05d151ad9754457ea68e44b231110208"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/15 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c97849e8ed74267a6e3db7989864a36"}},"metadata":{}},{"name":"stdout","text":"Shapes of the datasets:\nTraining: (203, 3)\nValidation: (44, 3)\nDev: (28, 3)\nTest: (15, 3)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"Helper method to generate text based on prompt","metadata":{}},{"cell_type":"code","source":"def gen(model, p, maxlen=100, sample=True, seed=GLOBAL_SEED):\n    toks = eval_tokenizer(p, return_tensors=\"pt\")\n    res = model.generate(\n        **toks.to(\"cuda\"), \n        max_new_tokens=maxlen, \n        do_sample=sample,\n        num_return_sequences=1,\n        temperature=0.1,\n        num_beams=1,\n        top_p=0.95,\n    ).to('cpu')\n    return eval_tokenizer.batch_decode(res, skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2025-05-12T22:23:25.280217Z","iopub.execute_input":"2025-05-12T22:23:25.280434Z","iopub.status.idle":"2025-05-12T22:23:25.284798Z","shell.execute_reply.started":"2025-05-12T22:23:25.280418Z","shell.execute_reply":"2025-05-12T22:23:25.284265Z"},"id":"bd4liREwSkTw","trusted":true},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"Try out to generate text with baseline model","metadata":{}},{"cell_type":"code","source":"%%time\nindex = 10\n\narticle = dataset['test'][index]['article']\nsummary = dataset['test'][index]['highlights']\n\nformatted_prompt = f\"Instruct: Summarize the following article.\\n{article}\\nOutput:\\n\"\nres = gen(original_model, formatted_prompt, 100,)\noutput = res[0].split('Output:\\n')[1]\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{formatted_prompt}')\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - ZERO SHOT:\\n{output}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-05-12T22:23:25.285689Z","iopub.execute_input":"2025-05-12T22:23:25.285939Z","iopub.status.idle":"2025-05-12T22:23:29.085092Z","shell.execute_reply.started":"2025-05-12T22:23:25.285919Z","shell.execute_reply":"2025-05-12T22:23:29.084303Z"},"id":"A_gmNFEVSzKB","outputId":"91503dcd-b140-408d-a8e2-ad8f2badf554","trusted":true},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"---------------------------------------------------------------------------------------------------\nINPUT PROMPT:\nInstruct: Summarize the following article.\nLondon (CNN)A 19-year-old man was charged Wednesday with terror offenses after he was arrested as he returned to Britain from Turkey, London's Metropolitan Police said. Yahya Rashid, a UK national from northwest London, was detained at Luton airport on Tuesday after he arrived on a flight from Istanbul, police said. He's been charged with engaging in conduct in preparation of acts of terrorism, and with engaging in conduct with the intention of assisting others to commit acts of terrorism. Both charges relate to the period between November 1 and March 31. Rashid is due to appear in Westminster Magistrates' Court on Wednesday, police said. CNN's Lindsay Isaac contributed to this report.\nOutput:\n\n---------------------------------------------------------------------------------------------------\nBASELINE HUMAN SUMMARY:\nLondon's Metropolitan Police say the man was arrested at Luton airport after landing on a flight from Istanbul .\nHe's been charged with terror offenses allegedly committed since the start of November .\n\n---------------------------------------------------------------------------------------------------\nMODEL GENERATION - ZERO SHOT:\nA 19-year-old man from northwest London was arrested at Luton airport on Tuesday after returning to Britain from Turkey. He was charged with engaging in conduct in preparation of acts of terrorism and engaging in conduct with the intention of assisting others to commit acts of terrorism. The charges relate to the period between November 1 and March 31. He is due to appear in Westminster Magistrates' Court on Wednesday.\n\nCPU times: user 3.33 s, sys: 64.3 ms, total: 3.4 s\nWall time: 3.78 s\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"def print_gpu_utilization():\n    nvmlInit()\n    handle = nvmlDeviceGetHandleByIndex(0)\n    info = nvmlDeviceGetMemoryInfo(handle)\n    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:23:29.085919Z","iopub.execute_input":"2025-05-12T22:23:29.086169Z","iopub.status.idle":"2025-05-12T22:23:29.089888Z","shell.execute_reply.started":"2025-05-12T22:23:29.086147Z","shell.execute_reply":"2025-05-12T22:23:29.089347Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def print_number_of_trainable_model_parameters(model):\n    trainable_model_params = 0\n    all_model_params = 0\n    for _, param in model.named_parameters():\n        all_model_params += param.numel()\n        if param.requires_grad:\n            trainable_model_params += param.numel()\n    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-05-12T22:23:29.090500Z","iopub.execute_input":"2025-05-12T22:23:29.090699Z","iopub.status.idle":"2025-05-12T22:23:29.105360Z","shell.execute_reply.started":"2025-05-12T22:23:29.090684Z","shell.execute_reply":"2025-05-12T22:23:29.104645Z"},"id":"yuoK0dCkT0az","outputId":"0a7e60de-ce3c-45e2-8bca-10afe480df43","trusted":true},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"Compare original model with ones that will have LoRA Adapter attached. LoRA is used to help fine-tune more efficiently","metadata":{}},{"cell_type":"code","source":"print(print_number_of_trainable_model_parameters(original_model))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:23:29.105980Z","iopub.execute_input":"2025-05-12T22:23:29.106132Z","iopub.status.idle":"2025-05-12T22:23:29.121761Z","shell.execute_reply.started":"2025-05-12T22:23:29.106120Z","shell.execute_reply":"2025-05-12T22:23:29.121172Z"}},"outputs":[{"name":"stdout","text":"trainable model parameters: 262364160\nall model parameters: 1521392640\npercentage of trainable model parameters: 17.24%\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"print(original_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-05-12T22:23:29.122501Z","iopub.execute_input":"2025-05-12T22:23:29.122730Z","iopub.status.idle":"2025-05-12T22:23:29.137582Z","shell.execute_reply.started":"2025-05-12T22:23:29.122710Z","shell.execute_reply":"2025-05-12T22:23:29.136876Z"},"id":"IOm68qZZT4q8","outputId":"ebc0fc75-f765-4729-e10e-7874d10da5e0","trusted":true},"outputs":[{"name":"stdout","text":"PhiForCausalLM(\n  (model): PhiModel(\n    (embed_tokens): Embedding(51200, 2560)\n    (layers): ModuleList(\n      (0-31): 32 x PhiDecoderLayer(\n        (self_attn): PhiAttention(\n          (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (v_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n        )\n        (mlp): PhiMLP(\n          (activation_fn): NewGELUActivation()\n          (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n          (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n        )\n        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (rotary_emb): PhiRotaryEmbedding()\n    (embed_dropout): Dropout(p=0.0, inplace=False)\n    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n\nconfig = LoraConfig(\n    r=32,\n    lora_alpha=32,\n    target_modules=[\n        'q_proj',\n        'k_proj',\n        'v_proj',\n        'dense'\n    ],\n    bias=\"none\",\n    lora_dropout=0.05,\n    task_type=\"CAUSAL_LM\",\n)\n\noriginal_model.gradient_checkpointing_enable()\n\noriginal_model = prepare_model_for_kbit_training(original_model)\n\npeft_model = get_peft_model(original_model, config)","metadata":{"execution":{"iopub.status.busy":"2025-05-12T22:23:29.138210Z","iopub.execute_input":"2025-05-12T22:23:29.138406Z","iopub.status.idle":"2025-05-12T22:23:29.512416Z","shell.execute_reply.started":"2025-05-12T22:23:29.138391Z","shell.execute_reply":"2025-05-12T22:23:29.511783Z"},"id":"djYOCCntT7rK","trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":"print(print_number_of_trainable_model_parameters(peft_model))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-05-12T22:23:29.513081Z","iopub.execute_input":"2025-05-12T22:23:29.513267Z","iopub.status.idle":"2025-05-12T22:23:29.520911Z","shell.execute_reply.started":"2025-05-12T22:23:29.513253Z","shell.execute_reply":"2025-05-12T22:23:29.520276Z"},"id":"x8gOrr9IUG8X","outputId":"07b801c3-1ba4-4e24-976b-e569196866b6","trusted":true},"outputs":[{"name":"stdout","text":"trainable model parameters: 20971520\nall model parameters: 1542364160\npercentage of trainable model parameters: 1.36%\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(peft_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-05-12T22:23:29.524285Z","iopub.execute_input":"2025-05-12T22:23:29.524565Z","iopub.status.idle":"2025-05-12T22:23:29.542065Z","shell.execute_reply.started":"2025-05-12T22:23:29.524548Z","shell.execute_reply":"2025-05-12T22:23:29.541351Z"},"id":"i27yzRadUKUN","outputId":"6a2c6de8-b212-4795-bf38-18b233844c2c","trusted":true},"outputs":[{"name":"stdout","text":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): PhiForCausalLM(\n      (model): PhiModel(\n        (embed_tokens): Embedding(51200, 2560)\n        (layers): ModuleList(\n          (0-31): 32 x PhiDecoderLayer(\n            (self_attn): PhiAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2560, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=2560, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2560, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=2560, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2560, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=2560, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (dense): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=2560, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=32, out_features=2560, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n            )\n            (mlp): PhiMLP(\n              (activation_fn): NewGELUActivation()\n              (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n              (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n            )\n            (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n            (resid_dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (rotary_emb): PhiRotaryEmbedding()\n        (embed_dropout): Dropout(p=0.0, inplace=False)\n        (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      )\n      (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n    )\n  )\n)\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"print_gpu_utilization()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:23:29.542913Z","iopub.execute_input":"2025-05-12T22:23:29.543196Z","iopub.status.idle":"2025-05-12T22:23:29.556875Z","shell.execute_reply.started":"2025-05-12T22:23:29.543173Z","shell.execute_reply":"2025-05-12T22:23:29.556253Z"}},"outputs":[{"name":"stdout","text":"GPU memory occupied: 3708 MB.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"output_dir = './peft-dialogue-summary-training/final-checkpoint'\nimport transformers\n\npeft_training_args = TrainingArguments(\n    output_dir = output_dir,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=4,\n    max_steps=10,\n    learning_rate=2e-4,\n    optim=\"paged_adamw_8bit\",\n    logging_steps=10,\n    logging_dir=\"./logs\",\n    save_strategy=\"steps\",\n    save_steps=10,\n    eval_strategy=\"steps\",\n    eval_steps=10,\n    num_train_epochs=1,\n    do_eval=True,\n    gradient_checkpointing=True,\n    report_to=\"none\",\n    overwrite_output_dir = 'True',\n    group_by_length=True,\n    seed=GLOBAL_SEED,\n    data_seed=GLOBAL_SEED\n)\n\npeft_model.config.use_cache = False\n\npeft_trainer = transformers.Trainer(\n    model=peft_model,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    args=peft_training_args,\n    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-05-12T22:23:29.557587Z","iopub.execute_input":"2025-05-12T22:23:29.557820Z","iopub.status.idle":"2025-05-12T22:23:29.611745Z","shell.execute_reply.started":"2025-05-12T22:23:29.557795Z","shell.execute_reply":"2025-05-12T22:23:29.610833Z"},"id":"ijGOIAJAUQjK","outputId":"b361a160-805e-4d39-9469-95f1835e824f","trusted":true},"outputs":[{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"peft_training_args.device","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-05-12T22:23:29.612631Z","iopub.execute_input":"2025-05-12T22:23:29.613735Z","iopub.status.idle":"2025-05-12T22:23:29.619354Z","shell.execute_reply.started":"2025-05-12T22:23:29.613707Z","shell.execute_reply":"2025-05-12T22:23:29.618259Z"},"id":"koz0-4PHUZzX","outputId":"8439479e-1eed-4b12-86b0-c539e6cc6fef","trusted":true},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"peft_trainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"execution":{"iopub.status.busy":"2025-05-12T22:23:29.620234Z","iopub.execute_input":"2025-05-12T22:23:29.620507Z","iopub.status.idle":"2025-05-12T22:27:04.235923Z","shell.execute_reply.started":"2025-05-12T22:23:29.620482Z","shell.execute_reply":"2025-05-12T22:27:04.235351Z"},"id":"FFcxA1B-UfJ1","outputId":"61ea5329-96a8-47f7-d188-f68db5d163fb","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10/10 03:08, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.437600</td>\n      <td>2.414258</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=10, training_loss=2.4376129150390624, metrics={'train_runtime': 213.907, 'train_samples_per_second': 0.187, 'train_steps_per_second': 0.047, 'total_flos': 667241004165120.0, 'train_loss': 2.4376129150390624, 'epoch': 0.19704433497536947})"},"metadata":{}}],"execution_count":32},{"cell_type":"markdown","source":"Free memory for further steps","metadata":{}},{"cell_type":"code","source":"print_gpu_utilization()","metadata":{"execution":{"iopub.status.busy":"2025-05-12T22:27:04.236651Z","iopub.execute_input":"2025-05-12T22:27:04.237045Z","iopub.status.idle":"2025-05-12T22:27:04.241423Z","shell.execute_reply.started":"2025-05-12T22:27:04.237021Z","shell.execute_reply":"2025-05-12T22:27:04.240686Z"},"id":"QajO3VMeXWAV","trusted":true},"outputs":[{"name":"stdout","text":"GPU memory occupied: 14830 MB.\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"print_gpu_utilization()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:27:04.242022Z","iopub.execute_input":"2025-05-12T22:27:04.242189Z","iopub.status.idle":"2025-05-12T22:27:04.255916Z","shell.execute_reply.started":"2025-05-12T22:27:04.242175Z","shell.execute_reply":"2025-05-12T22:27:04.255210Z"}},"outputs":[{"name":"stdout","text":"GPU memory occupied: 14830 MB.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"print(\"Evaluating on Dev split...\")\ndev_results = peft_trainer.evaluate(dev_dataset)\nprint(f\"Dev set evaluation results:\")\nprint(dev_results)","metadata":{"execution":{"iopub.status.busy":"2025-05-12T22:27:04.256702Z","iopub.execute_input":"2025-05-12T22:27:04.256971Z","iopub.status.idle":"2025-05-12T22:27:48.070000Z","shell.execute_reply.started":"2025-05-12T22:27:04.256955Z","shell.execute_reply":"2025-05-12T22:27:48.069193Z"},"id":"oWuUsgZY_k0O","trusted":true},"outputs":[{"name":"stdout","text":"Evaluating on Dev split...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4/4 00:59]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Dev set evaluation results:\n{'eval_loss': 2.339982748031616, 'eval_runtime': 43.7738, 'eval_samples_per_second': 0.64, 'eval_steps_per_second': 0.091, 'epoch': 0.19704433497536947}\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"print(\"Performing final evaluation on Test split...\")\ntest_results = peft_trainer.evaluate(test_dataset)\nprint(f\"Final test set evaluation results:\")\nprint(test_results)","metadata":{"execution":{"iopub.status.busy":"2025-05-12T22:27:48.070844Z","iopub.execute_input":"2025-05-12T22:27:48.071033Z","iopub.status.idle":"2025-05-12T22:28:19.085670Z","shell.execute_reply.started":"2025-05-12T22:27:48.071018Z","shell.execute_reply":"2025-05-12T22:28:19.084995Z"},"id":"ZgraAjRO_k0O","trusted":true},"outputs":[{"name":"stdout","text":"Performing final evaluation on Test split...\nFinal test set evaluation results:\n{'eval_loss': 2.446943998336792, 'eval_runtime': 30.9891, 'eval_samples_per_second': 0.484, 'eval_steps_per_second': 0.065, 'epoch': 0.19704433497536947}\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"import pandas as pd\nimport evaluate\nimport torch\nimport numpy as np\n\narticles = new_test_dataset[15:25]['article']\nhuman_baseline_summaries = new_test_dataset[15:25]['highlights']\n\noriginal_model_summaries = []\npeft_model_summaries = []\n\nfor idx, article in enumerate(articles):\n    human_baseline_text_output = human_baseline_summaries[idx]\n    \n    prompt = f\"\\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruct: Summarize the below article.\\n\\n{article}\\n\\n### Output:\\n\"\n\n    original_model_res = gen(original_model, prompt, 150)\n    \n    try:\n        if '### Output:' in original_model_res[0]:\n            original_model_text_output = original_model_res[0].split('### Output:')[1].strip()\n        elif 'Output:' in original_model_res[0]:\n            original_model_text_output = original_model_res[0].split('Output:')[1].strip()\n        else:\n            original_model_text_output = original_model_res[0]\n    except Exception as e:\n        print(f\"Error parsing original model output for article {idx}: {e}\")\n        original_model_text_output = \"[Parsing error]\"\n\n    peft_model_res = gen(peft_model, prompt, 150)\n    \n    try:\n        if '### Output:' in peft_model_res[0]:\n            peft_model_output = peft_model_res[0].split('### Output:')[1].strip()\n        elif 'Output:' in peft_model_res[0]:\n            peft_model_output = peft_model_res[0].split('Output:')[1].strip()\n        else:\n            peft_model_output = peft_model_res[0]\n            \n        for marker in ['### End', '#End', '##OUTPUT', '##End']:\n            if marker in peft_model_output:\n                peft_model_text_output = peft_model_output.split(marker)[0].strip()\n                break\n        else:\n            peft_model_text_output = peft_model_output.strip()\n            \n    except Exception as e:\n        print(f\"Error parsing PEFT model output for article {idx}: {e}\")\n        peft_model_text_output = \"[Parsing error]\"\n\n    original_model_summaries.append(original_model_text_output)\n    peft_model_summaries.append(peft_model_text_output)\n\nzipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, peft_model_summaries))\n\ndf = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'peft_model_summaries'])\ndf","metadata":{"execution":{"iopub.status.busy":"2025-05-12T22:28:19.086410Z","iopub.execute_input":"2025-05-12T22:28:19.086632Z","iopub.status.idle":"2025-05-12T22:32:01.403202Z","shell.execute_reply.started":"2025-05-12T22:28:19.086615Z","shell.execute_reply":"2025-05-12T22:32:01.402586Z"},"id":"EIPSiTRWbJs3","trusted":true},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"                            human_baseline_summaries  \\\n0  France announces new ministers .\\nThe governme...   \n1  Miss California USA Carrie Prejean says she po...   \n2  Jay-Z reported to be 'deeply disappointed' by ...   \n3  Carbisdale Castle near Culrain is nestled on p...   \n4  Police collated the four-page dossier followin...   \n5  She still owns £3.9 million stately home in Ea...   \n6  Mitt Romney is trying to outdo President Obama...   \n7  Archaeologists believe site was centre of a ne...   \n8  Edward Snowden claimed that a damaging culture...   \n9  Enterovirus D68 is sending children with breat...   \n\n                            original_model_summaries  \\\n0  A new French government was announced Tuesday,...   \n1  A second lingerie-modeling photo of Miss Calif...   \n2  Rihanna was pictured out in London today looki...   \n3  Carbisdale Castle, near the village of Culrain...   \n4  An unnamed hit band from the 1960s attended th...   \n5  Heather Mills has sold her British beachfront ...   \n6  The article is about how Mitt Romney is trying...   \n7  The article describes how archaeologists have ...   \n8  Edward Snowden, who worked as a contract emplo...   \n9  Enterovirus D68 has swept through 30 states si...   \n\n                                peft_model_summaries  \n0  A new French government was announced on Tuesd...  \n1  A second lingerie-modeling photo of Miss Calif...  \n2  Rihanna was pictured out in London today looki...  \n3  Carbisdale Castle, near the Highland village o...  \n4  An unnamed hit band from the 1960s attended th...  \n5  Heather Mills has sold her British beachfront ...  \n6  The article is about how Mitt Romney is trying...  \n7  The article discusses the latest discovery of ...  \n8  Edward Snowden, who worked as a contract emplo...  \n9  Enterovirus D68 has swept through 30 states si...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>human_baseline_summaries</th>\n      <th>original_model_summaries</th>\n      <th>peft_model_summaries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>France announces new ministers .\\nThe governme...</td>\n      <td>A new French government was announced Tuesday,...</td>\n      <td>A new French government was announced on Tuesd...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Miss California USA Carrie Prejean says she po...</td>\n      <td>A second lingerie-modeling photo of Miss Calif...</td>\n      <td>A second lingerie-modeling photo of Miss Calif...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Jay-Z reported to be 'deeply disappointed' by ...</td>\n      <td>Rihanna was pictured out in London today looki...</td>\n      <td>Rihanna was pictured out in London today looki...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Carbisdale Castle near Culrain is nestled on p...</td>\n      <td>Carbisdale Castle, near the village of Culrain...</td>\n      <td>Carbisdale Castle, near the Highland village o...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Police collated the four-page dossier followin...</td>\n      <td>An unnamed hit band from the 1960s attended th...</td>\n      <td>An unnamed hit band from the 1960s attended th...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>She still owns £3.9 million stately home in Ea...</td>\n      <td>Heather Mills has sold her British beachfront ...</td>\n      <td>Heather Mills has sold her British beachfront ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Mitt Romney is trying to outdo President Obama...</td>\n      <td>The article is about how Mitt Romney is trying...</td>\n      <td>The article is about how Mitt Romney is trying...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Archaeologists believe site was centre of a ne...</td>\n      <td>The article describes how archaeologists have ...</td>\n      <td>The article discusses the latest discovery of ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Edward Snowden claimed that a damaging culture...</td>\n      <td>Edward Snowden, who worked as a contract emplo...</td>\n      <td>Edward Snowden, who worked as a contract emplo...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Enterovirus D68 is sending children with breat...</td>\n      <td>Enterovirus D68 has swept through 30 states si...</td>\n      <td>Enterovirus D68 has swept through 30 states si...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"import evaluate\nrouge = evaluate.load('rouge')\n\noriginal_model_results = rouge.compute(\n    predictions=original_model_summaries,\n    references=human_baseline_summaries[0:len(original_model_summaries)],\n    use_aggregator=True,\n    use_stemmer=True,\n)\n\npeft_model_results = rouge.compute(\n    predictions=peft_model_summaries,\n    references=human_baseline_summaries[0:len(peft_model_summaries)],\n    use_aggregator=True,\n    use_stemmer=True,\n)\n\nbleu = evaluate.load('bleu')\n\noriginal_model_bleu = bleu.compute(\n    predictions=original_model_summaries,\n    references=[[ref] for ref in human_baseline_summaries]\n)\n\npeft_model_bleu = bleu.compute(\n    predictions=peft_model_summaries, \n    references=[[ref] for ref in human_baseline_summaries]\n)\n\ndef calculate_perplexity_alt(model, tokenizer, texts, max_loss=20.0):\n    perplexities = []\n    \n    with torch.no_grad():\n        for text in texts:\n            try:\n                inputs = tokenizer(text, return_tensors=\"pt\")\n                inputs = {k: v.to(model.device) for k, v in inputs.items()}\n                \n                outputs = model(**inputs)\n                logits = outputs.logits\n                \n                shift_logits = logits[..., :-1, :].contiguous()\n                shift_labels = inputs['input_ids'][..., 1:].contiguous()\n                \n                loss_fct = torch.nn.CrossEntropyLoss(reduction='mean')\n                loss = loss_fct(shift_logits.reshape(-1, shift_logits.size(-1)), \n                              shift_labels.reshape(-1))\n                \n                loss = torch.clamp(loss, 0, max_loss)\n                \n                perplexity = torch.exp(loss)\n                \n                if not torch.isnan(perplexity) and not torch.isinf(perplexity):\n                    perplexities.append(perplexity.item())\n            except Exception as e:\n                print(f\"Error processing text: {e}\")\n                continue\n    \n    if not perplexities:\n        return float('nan')\n    \n    return sum(perplexities) / len(perplexities)\n\noriginal_perplexity = calculate_perplexity_alt(original_model, eval_tokenizer, human_baseline_summaries)\npeft_perplexity = calculate_perplexity_alt(peft_model, eval_tokenizer, peft_model_summaries)\n\ndef format_metrics(rouge_results, bleu_results, perplexity):\n    print(\"=== ROUGE Scores ===\")\n    for metric, value in rouge_results.items():\n        print(f\"  {metric}: {value*100:.2f}%\")\n    \n    print(\"\\n=== BLEU Score ===\")\n    print(f\"  BLEU: {bleu_results['bleu']*100:.2f}%\")\n    print(\"  Precision by n-gram:\")\n    for n, precision in enumerate(bleu_results['precisions'], 1):\n        print(f\"    {n}-gram: {precision*100:.2f}%\")\n    \n    print(f\"\\n=== Perplexity ===\")\n    print(f\"  {perplexity:.4f} (lower is better)\")\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"ORIGINAL MODEL EVALUATION\")\nprint(\"=\"*50)\nformat_metrics(original_model_results, original_model_bleu, original_perplexity)\n\nprint(\"\\n\\n\" + \"=\"*50)\nprint(\"PEFT MODEL EVALUATION\")\nprint(\"=\"*50)\nformat_metrics(peft_model_results, peft_model_bleu, peft_perplexity)\n\nprint(\"\\n\\n\" + \"=\"*50)\nprint(\"IMPROVEMENT SUMMARY\")\nprint(\"=\"*50)\n\nprint(\"=== ROUGE Improvement ===\")\nfor metric in original_model_results.keys():\n    improvement = (peft_model_results[metric] - original_model_results[metric]) * 100\n    print(f\"  {metric}: {improvement:.2f}% absolute improvement\")\n\nbleu_improvement = (peft_model_bleu['bleu'] - original_model_bleu['bleu']) * 100\nprint(\"\\n=== BLEU Improvement ===\")\nprint(f\"  {bleu_improvement:.2f}% absolute improvement\")\n\nperplexity_improvement = original_perplexity - peft_perplexity\nperplexity_improvement_percent = (perplexity_improvement / original_perplexity) * 100\nprint(\"\\n=== Perplexity Improvement ===\")\nprint(f\"  {perplexity_improvement_percent:.2f}% reduction\")","metadata":{"execution":{"iopub.status.busy":"2025-05-12T22:32:01.403942Z","iopub.execute_input":"2025-05-12T22:32:01.404117Z","iopub.status.idle":"2025-05-12T22:32:08.292363Z","shell.execute_reply.started":"2025-05-12T22:32:01.404104Z","shell.execute_reply":"2025-05-12T22:32:08.291511Z"},"id":"4VLiakHMbu_U","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0064af1574a44c63b28c1d8e71cdcb7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f18970715d74d18b67ea9093d43c034"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0b8e6bafd054819bf97884d598ec9a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0602db2ba9e2492d81179bccd8602368"}},"metadata":{}},{"name":"stdout","text":"\n==================================================\nORIGINAL MODEL EVALUATION\n==================================================\n=== ROUGE Scores ===\n  rouge1: 31.80%\n  rouge2: 9.84%\n  rougeL: 19.20%\n  rougeLsum: 23.78%\n\n=== BLEU Score ===\n  BLEU: 4.67%\n  Precision by n-gram:\n    1-gram: 22.34%\n    2-gram: 6.16%\n    3-gram: 2.87%\n    4-gram: 1.20%\n\n=== Perplexity ===\n  44.5138 (lower is better)\n\n\n==================================================\nPEFT MODEL EVALUATION\n==================================================\n=== ROUGE Scores ===\n  rouge1: 31.32%\n  rouge2: 10.37%\n  rougeL: 19.25%\n  rougeLsum: 24.23%\n\n=== BLEU Score ===\n  BLEU: 4.68%\n  Precision by n-gram:\n    1-gram: 21.94%\n    2-gram: 6.24%\n    3-gram: 2.80%\n    4-gram: 1.25%\n\n=== Perplexity ===\n  11.9945 (lower is better)\n\n\n==================================================\nIMPROVEMENT SUMMARY\n==================================================\n=== ROUGE Improvement ===\n  rouge1: -0.48% absolute improvement\n  rouge2: 0.54% absolute improvement\n  rougeL: 0.05% absolute improvement\n  rougeLsum: 0.45% absolute improvement\n\n=== BLEU Improvement ===\n  0.01% absolute improvement\n\n=== Perplexity Improvement ===\n  73.05% reduction\n","output_type":"stream"}],"execution_count":38}]}