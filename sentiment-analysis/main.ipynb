{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c5f4269",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook explores DistilBERT that is fine tuned to do sentiment analysis on sst2 dataset. The baseline as comparison is DistillBERT without fine tuning and a machine learning SVM model. Evaluation uses accuracy, precision, recall and f1 score\n",
    "\n",
    "Muhammad Adnan Rizqullah (2403851)\n",
    "\n",
    "**Requirements:** This notebook is tested to run with Python 3.11.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e29ca3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.11\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "required_version = \"3.11.11\"\n",
    "current_version = sys.version.split()[0]\n",
    "\n",
    "if current_version != required_version:\n",
    "    warnings.warn(f\"âš ï¸ This notebook is tested to run with Python {current_version}. Proceeding may cause compatibility issues.\")\n",
    "    \n",
    "print(f\"Python version: {current_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb0fed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets==3.6.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (3.6.0)\n",
      "Requirement already satisfied: matplotlib==3.10.3 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (3.10.3)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (0.1.6)\n",
      "Requirement already satisfied: numpy==2.2.5 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.2.5)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (1.6.1)\n",
      "Requirement already satisfied: torch==2.7.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (2.7.0)\n",
      "Requirement already satisfied: transformers==4.51.3 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (4.51.3)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.6.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (0.31.1)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from datasets==3.6.0->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from matplotlib==3.10.3->-r requirements.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from matplotlib==3.10.3->-r requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from matplotlib==3.10.3->-r requirements.txt (line 2)) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from matplotlib==3.10.3->-r requirements.txt (line 2)) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from matplotlib==3.10.3->-r requirements.txt (line 2)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from matplotlib==3.10.3->-r requirements.txt (line 2)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from matplotlib==3.10.3->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: traitlets in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from matplotlib-inline==0.1.6->-r requirements.txt (line 3)) (5.14.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from scikit-learn==1.6.1->-r requirements.txt (line 5)) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from scikit-learn==1.6.1->-r requirements.txt (line 5)) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from scikit-learn==1.6.1->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from torch==2.7.0->-r requirements.txt (line 6)) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from torch==2.7.0->-r requirements.txt (line 6)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from torch==2.7.0->-r requirements.txt (line 6)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from torch==2.7.0->-r requirements.txt (line 6)) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from transformers==4.51.3->-r requirements.txt (line 7)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from transformers==4.51.3->-r requirements.txt (line 7)) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from transformers==4.51.3->-r requirements.txt (line 7)) (0.5.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (3.11.18)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets==3.6.0->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: psutil in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from accelerate>=0.26.0->-r requirements.txt (line 8)) (5.9.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib==3.10.3->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.6.0->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.6.0->-r requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from requests>=2.32.2->datasets==3.6.0->-r requirements.txt (line 1)) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.7.0->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from jinja2->torch==2.7.0->-r requirements.txt (line 6)) (3.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from pandas->datasets==3.6.0->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages (from pandas->datasets==3.6.0->-r requirements.txt (line 1)) (2025.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Google Colab, installing missing packages...\")\n",
    "    %pip install datasets\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running in Google Colab, installing from requirements file...\")\n",
    "    %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96364735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "from transformers import set_seed\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from datasets import concatenate_datasets\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "868a8051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon GPU (MPS)\n"
     ]
    }
   ],
   "source": [
    "def get_device_info():\n",
    "    \"\"\"Detect and return the best available device with its capabilities\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        device_name = torch.cuda.get_device_name(0)\n",
    "        device_type = \"CUDA\"\n",
    "        supports_fp16 = True  # CUDA generally supports fp16\n",
    "        max_batch_size = 32  # Typical for T4 GPUs\n",
    "        print(f\"Using CUDA GPU: {device_name}\")\n",
    "    elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "        device = torch.device(\"mps\")\n",
    "        device_name = \"Apple Silicon\"\n",
    "        device_type = \"MPS\"\n",
    "        supports_fp16 = False  # MPS has limited fp16 support\n",
    "        max_batch_size = 16   # Conservative for M1 chips\n",
    "        print(f\"Using Apple Silicon GPU (MPS)\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        device_name = \"CPU\"\n",
    "        device_type = \"CPU\"\n",
    "        supports_fp16 = False\n",
    "        max_batch_size = 8  # Conservative for CPU\n",
    "        print(\"Using CPU (no GPU available)\")\n",
    "    \n",
    "    return {\n",
    "        \"device\": device,\n",
    "        \"name\": device_name,\n",
    "        \"type\": device_type,\n",
    "        \"supports_fp16\": supports_fp16,\n",
    "        \"max_batch_size\": max_batch_size\n",
    "    }\n",
    "\n",
    "# Get device information\n",
    "device_info = get_device_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f604b78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon GPU (MPS)\n",
      "Configuration loaded successfully for MPS\n"
     ]
    }
   ],
   "source": [
    "# Get optimal device-specific settings\n",
    "device_info = get_device_info()\n",
    "\n",
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"model_name\": \"distilbert-base-uncased\",\n",
    "    \"model_num_labels\": 2,\n",
    "    \"dataset_name\": \"stanfordnlp/sst2\",\n",
    "    \"train_split_ratio\": 0.7,\n",
    "    \"validation_split_ratio\": 0.15,\n",
    "    \"dev_split_ratio\": 0.1,\n",
    "    \"test_split_ratio\": 0.05,\n",
    "    # Dynamically set data sizes based on available hardware\n",
    "    \"train_subset_size\": 1750 if device_info[\"type\"] in [\"CUDA\"] else 200,\n",
    "    \"validation_subset_size\": 325 if device_info[\"type\"] in [\"CUDA\"] else 50,\n",
    "    \"dev_subset_size\": 250 if device_info[\"type\"] in [\"CUDA\"] else 50,\n",
    "    \"test_subset_size\": 125 if device_info[\"type\"] in [\"CUDA\"] else 50,\n",
    "    \"num_proc\": 4,\n",
    "    \"tokenizer_padding\": \"max_length\",\n",
    "    \"tokenizer_truncation\": True,\n",
    "    \"tokenizer_max_length\": 512,\n",
    "    \"output_dir\": \"./results\",\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"train_batch_size\": device_info[\"max_batch_size\"],\n",
    "    \"eval_batch_size\": device_info[\"max_batch_size\"] * 2,\n",
    "    \"num_epochs\": 5,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    # Device-specific settings\n",
    "    \"device\": device_info[\"device\"],\n",
    "    \"device_type\": device_info[\"type\"],\n",
    "    \"fp16\": device_info[\"supports_fp16\"],\n",
    "    \"gradient_accumulation_steps\": 2\n",
    "}\n",
    "\n",
    "print(f\"Configuration loaded successfully for {config['device_type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d751cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All random seeds have been set to 42 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "SEED = config[\"seed\"]\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Device-specific seeding\n",
    "if config[\"device_type\"] == \"CUDA\":\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    print(\"CUDA seed set\")\n",
    "\n",
    "set_seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "\n",
    "print(f\"All random seeds have been set to {SEED} for reproducibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f100c7c",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "This section analyzes and prepares the dataset for training:\n",
    "1. Explored the number of rows and labels distribution\n",
    "2. Use down-sampling to balance the dataset to have equal number of labels for each label\n",
    "3. Explored how the text content looks like in the dataset\n",
    "4. Split the dataset into training, validation, dev, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44bf48de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(config[\"dataset_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a81d46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info:\n",
      "Dataset type: <class 'datasets.dataset_dict.DatasetDict'>\n",
      "Dataset splits: dict_keys(['train', 'validation', 'test'])\n",
      "\n",
      "Number of examples per split:\n",
      "  train: 67349\n",
      "  validation: 872\n",
      "  test: 1821\n",
      "\n",
      "Features in the dataset:\n",
      "  idx: Value(dtype='int32', id=None)\n",
      "  sentence: Value(dtype='string', id=None)\n",
      "  label: ClassLabel(names=['negative', 'positive'], id=None)\n",
      "\n",
      "Label distribution:\n",
      "  train: {0: 29780, 1: 37569}\n",
      "  validation: {1: 444, 0: 428}\n",
      "  test: {-1: 1821}\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset info:\")\n",
    "print(f\"Dataset type: {type(dataset)}\")\n",
    "print(f\"Dataset splits: {dataset.keys()}\")\n",
    "print(\"\\nNumber of examples per split:\")\n",
    "for split in dataset.keys():\n",
    "  print(f\"  {split}: {len(dataset[split])}\")\n",
    "\n",
    "print(\"\\nFeatures in the dataset:\")\n",
    "for feature in dataset['train'].features:\n",
    "  print(f\"  {feature}: {dataset['train'].features[feature]}\")\n",
    "\n",
    "print(\"\\nLabel distribution:\")\n",
    "for split in dataset.keys():\n",
    "  label_counts = {}\n",
    "  for label in dataset[split]['label']:\n",
    "    if label not in label_counts:\n",
    "      label_counts[label] = 0\n",
    "    label_counts[label] += 1\n",
    "  print(f\"  {split}: {label_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cc05f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training positive samples: 37569\n",
      "Original training negative samples: 29780\n",
      "Total samples in balanced training set: 59560\n",
      "Validation positive samples: 444\n",
      "Validation negative samples: 428\n",
      "Total samples in balanced validation set: 856\n",
      "\n",
      "Total samples in combined dataset: 60416\n",
      "Combined dataset label distribution: {1: 30208, 0: 30208}\n"
     ]
    }
   ],
   "source": [
    "train_positive = dataset['train'].filter(lambda example: example['label'] == 1)\n",
    "train_negative = dataset['train'].filter(lambda example: example['label'] == 0)\n",
    "\n",
    "print(f\"Original training positive samples: {len(train_positive)}\")\n",
    "print(f\"Original training negative samples: {len(train_negative)}\")\n",
    "\n",
    "positive_indices = np.random.choice(len(train_positive), len(train_negative), replace=False)\n",
    "downsampled_train_positive = train_positive.select(positive_indices)\n",
    "\n",
    "balanced_train = concatenate_datasets([downsampled_train_positive, train_negative])\n",
    "balanced_train = balanced_train.shuffle(seed=config[\"seed\"])\n",
    "\n",
    "print(f\"Total samples in balanced training set: {len(balanced_train)}\")\n",
    "\n",
    "val_positive = dataset['validation'].filter(lambda example: example['label'] == 1)\n",
    "val_negative = dataset['validation'].filter(lambda example: example['label'] == 0)\n",
    "\n",
    "print(f\"Validation positive samples: {len(val_positive)}\")\n",
    "print(f\"Validation negative samples: {len(val_negative)}\")\n",
    "\n",
    "if len(val_positive) > len(val_negative):\n",
    "    val_positive_indices = np.random.choice(len(val_positive), len(val_negative), replace=False)\n",
    "    balanced_val_positive = val_positive.select(val_positive_indices)\n",
    "    balanced_validation = concatenate_datasets([balanced_val_positive, val_negative])\n",
    "else:\n",
    "    val_negative_indices = np.random.choice(len(val_negative), len(val_positive), replace=False)\n",
    "    balanced_val_negative = val_negative.select(val_negative_indices)\n",
    "    balanced_validation = concatenate_datasets([val_positive, balanced_val_negative])\n",
    "\n",
    "balanced_validation = balanced_validation.shuffle(seed=config[\"seed\"])\n",
    "print(f\"Total samples in balanced validation set: {len(balanced_validation)}\")\n",
    "\n",
    "combined_dataset = concatenate_datasets([balanced_train, balanced_validation])\n",
    "combined_dataset = combined_dataset.shuffle(seed=config[\"seed\"])\n",
    "\n",
    "print(f\"\\nTotal samples in combined dataset: {len(combined_dataset)}\")\n",
    "\n",
    "combined_balance = {}\n",
    "for label in combined_dataset['label']:\n",
    "    if label not in combined_balance:\n",
    "        combined_balance[label] = 0\n",
    "    combined_balance[label] += 1\n",
    "print(f\"Combined dataset label distribution: {combined_balance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ac627d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text length statistics (characters):\n",
      "  Min: 2\n",
      "  Max: 268\n",
      "  Mean: 54.43\n",
      "  Median: 40.00\n",
      "\n",
      "Word count statistics:\n",
      "  Min: 1\n",
      "  Max: 52\n",
      "  Mean: 9.60\n",
      "  Median: 7.00\n",
      "\n",
      "Sample examples from combined dataset:\n",
      "  Example 1:\n",
      "    Text: the emotion is impressively true for being so hot-blooded \n",
      "    Label: 1 (Positive)\n",
      "\n",
      "  Example 2:\n",
      "    Text: botches \n",
      "    Label: 0 (Negative)\n",
      "\n",
      "  Example 3:\n",
      "    Text: tricky and satisfying as any of david \n",
      "    Label: 1 (Positive)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nText length statistics (characters):\")\n",
    "lengths = [len(text) for text in combined_dataset['sentence']]\n",
    "print(f\"  Min: {min(lengths)}\")\n",
    "print(f\"  Max: {max(lengths)}\")\n",
    "print(f\"  Mean: {np.mean(lengths):.2f}\")\n",
    "print(f\"  Median: {np.median(lengths):.2f}\")\n",
    "\n",
    "print(\"\\nWord count statistics:\")\n",
    "word_counts = [len(text.split()) for text in combined_dataset['sentence']]\n",
    "print(f\"  Min: {min(word_counts)}\")\n",
    "print(f\"  Max: {max(word_counts)}\")\n",
    "print(f\"  Mean: {np.mean(word_counts):.2f}\")\n",
    "print(f\"  Median: {np.median(word_counts):.2f}\")\n",
    "\n",
    "print(\"\\nSample examples from combined dataset:\")\n",
    "for i in range(3):  \n",
    "    print(f\"  Example {i+1}:\")\n",
    "    print(f\"    Text: {combined_dataset['sentence'][i]}\")\n",
    "    print(f\"    Label: {combined_dataset['label'][i]} ({['Negative', 'Positive'][combined_dataset['label'][i]]})\") \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c29d095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes: Train=42291, Val=9062, Dev=6041, Test=3022\n",
      "\n",
      "Final dataset sizes:\n",
      "Train: 42291 samples (70.0%)\n",
      "Validation: 9062 samples (15.0%)\n",
      "Dev: 6041 samples (10.0%)\n",
      "Test: 3022 samples (5.0%)\n",
      "Train label distribution: {1: 21226, 0: 21065}\n",
      "Validation label distribution: {1: 4508, 0: 4554}\n",
      "Dev label distribution: {0: 3107, 1: 2934}\n",
      "Test label distribution: {1: 1540, 0: 1482}\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(combined_dataset)\n",
    "\n",
    "train_size = int(dataset_size * config[\"train_split_ratio\"])\n",
    "val_size = int(dataset_size * config[\"validation_split_ratio\"])\n",
    "dev_size = int(dataset_size * config[\"dev_split_ratio\"])\n",
    "test_size = dataset_size - train_size - val_size - dev_size\n",
    "\n",
    "print(f\"Split sizes: Train={train_size}, Val={val_size}, Dev={dev_size}, Test={test_size}\")\n",
    "\n",
    "train_dataset = combined_dataset.select(range(train_size))\n",
    "val_dataset = combined_dataset.select(range(train_size, train_size + val_size))\n",
    "dev_dataset = combined_dataset.select(range(train_size + val_size, train_size + val_size + dev_size))\n",
    "test_dataset = combined_dataset.select(range(train_size + val_size + dev_size, dataset_size))\n",
    "\n",
    "print(f\"\\nFinal dataset sizes:\")\n",
    "print(f\"Train: {len(train_dataset)} samples ({len(train_dataset)/dataset_size*100:.1f}%)\")\n",
    "print(f\"Validation: {len(val_dataset)} samples ({len(val_dataset)/dataset_size*100:.1f}%)\")\n",
    "print(f\"Dev: {len(dev_dataset)} samples ({len(dev_dataset)/dataset_size*100:.1f}%)\")\n",
    "print(f\"Test: {len(test_dataset)} samples ({len(test_dataset)/dataset_size*100:.1f}%)\")\n",
    "\n",
    "for split_name, split_dataset in [(\"Train\", train_dataset), (\"Validation\", val_dataset), \n",
    "                                 (\"Dev\", dev_dataset), (\"Test\", test_dataset)]:\n",
    "    label_counts = {}\n",
    "    for label in split_dataset['label']:\n",
    "        if label not in label_counts:\n",
    "            label_counts[label] = 0\n",
    "        label_counts[label] += 1\n",
    "    print(f\"{split_name} label distribution: {label_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b479ff",
   "metadata": {},
   "source": [
    "## Model creation\n",
    "This section prepares the model and does the training:\n",
    "1. Tokenize dataset\n",
    "2. Determine metrics for training loss\n",
    "3. Determine the training hyper-parameters\n",
    "4. Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "698e7bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(config[\"model_name\"])\n",
    "model = DistilBertForSequenceClassification.from_pretrained(config[\"model_name\"], num_labels=config[\"model_num_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ba4450f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = DistilBertForSequenceClassification.from_pretrained(config[\"model_name\"], num_labels=config[\"model_num_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eb2e099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded and moved to MPS\n"
     ]
    }
   ],
   "source": [
    "# Move models to the appropriate device\n",
    "model = model.to(config[\"device\"])\n",
    "base_model = base_model.to(config[\"device\"])\n",
    "print(f\"Models loaded and moved to {config['device_type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7db0440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['sentence'], \n",
    "                    padding=config[\"tokenizer_padding\"], \n",
    "                    truncation=config[\"tokenizer_truncation\"],\n",
    "                    max_length=config[\"tokenizer_max_length\"])\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True, num_proc=config[\"num_proc\"])\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True, num_proc=config[\"num_proc\"])\n",
    "tokenized_dev = dev_dataset.map(tokenize_function, batched=True, num_proc=config[\"num_proc\"])\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True, num_proc=config[\"num_proc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11bbd5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a52e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages/transformers/training_args.py:2243: UserWarning: `use_mps_device` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. `mps` device will be used by default if available similar to the way `cuda` device is used.Therefore, no action from user is required. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=config[\"output_dir\"],\n",
    "    learning_rate=config[\"learning_rate\"],\n",
    "    per_device_train_batch_size=config[\"train_batch_size\"],\n",
    "    per_device_eval_batch_size=config[\"eval_batch_size\"],\n",
    "    num_train_epochs=config[\"num_epochs\"],\n",
    "    weight_decay=config[\"weight_decay\"],\n",
    "    eval_strategy=config[\"evaluation_strategy\"],\n",
    "    fp16=config[\"fp16\"],  # Uses FP16 only for CUDA devices\n",
    "    gradient_accumulation_steps=config[\"gradient_accumulation_steps\"],\n",
    "    # Handle special case for MPS\n",
    "    use_mps_device=(config[\"device_type\"] == \"MPS\"),\n",
    "    seed=config[\"seed\"],\n",
    "    data_seed=config[\"seed\"],\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29d172f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train.select(range(config[\"train_subset_size\"])),\n",
    "    eval_dataset=tokenized_val.select(range(config[\"validation_subset_size\"])),\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4da1c48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 01:35, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.705902</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.630137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12, training_loss=0.6631497542063395, metrics={'train_runtime': 102.1001, 'train_samples_per_second': 3.918, 'train_steps_per_second': 0.118, 'total_flos': 47688263516160.0, 'train_loss': 0.6631497542063395, 'epoch': 1.7692307692307692})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7241630a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SVM baseline model...\n",
      "Training SVM on 200 examples...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_features=10000, ngram_range=(1, 2))),\n",
       "                (&#x27;svm&#x27;, LinearSVC(dual=False, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_features=10000, ngram_range=(1, 2))),\n",
       "                (&#x27;svm&#x27;, LinearSVC(dual=False, random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(max_features=10000, ngram_range=(1, 2))</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearSVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC(dual=False, random_state=42)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_features=10000, ngram_range=(1, 2))),\n",
       "                ('svm', LinearSVC(dual=False, random_state=42))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Creating SVM baseline model...\")\n",
    "svm_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=10000, ngram_range=(1, 2))),\n",
    "    ('svm', LinearSVC(random_state=config[\"seed\"], dual=False))\n",
    "])\n",
    "\n",
    "X_train_subset = [train_dataset['sentence'][i] for i in range(config[\"train_subset_size\"])]\n",
    "y_train_subset = [train_dataset['label'][i] for i in range(config[\"train_subset_size\"])]\n",
    "\n",
    "print(f\"Training SVM on {len(X_train_subset)} examples...\")\n",
    "svm_pipeline.fit(X_train_subset, y_train_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d183a970",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "This section evaluates the each model and compares their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d184477e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "  eval_loss: 0.7059\n",
      "  eval_accuracy: 0.4600\n",
      "  eval_precision: 0.4600\n",
      "  eval_recall: 1.0000\n",
      "  eval_f1: 0.6301\n",
      "  eval_runtime: 5.2836\n",
      "  eval_samples_per_second: 9.4630\n",
      "  eval_steps_per_second: 0.3790\n",
      "  epoch: 1.7692\n"
     ]
    }
   ],
   "source": [
    "val_results = trainer.evaluate()\n",
    "print(\"\\nValidation Results:\")\n",
    "for key, value in val_results.items():\n",
    "  if isinstance(value, float):\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "  else:\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddb0ca0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dev set evaluation results:\n",
      "  eval_loss: 0.7013\n",
      "  eval_model_preparation_time: 0.0007\n",
      "  eval_accuracy: 0.4200\n",
      "  eval_precision: 0.4200\n",
      "  eval_recall: 1.0000\n",
      "  eval_f1: 0.5915\n",
      "  eval_runtime: 3.8348\n",
      "  eval_samples_per_second: 13.0380\n",
      "  eval_steps_per_second: 0.5220\n"
     ]
    }
   ],
   "source": [
    "dev_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_dev.select(range(config[\"dev_subset_size\"])),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "dev_results = dev_trainer.evaluate()\n",
    "print(\"\\nDev set evaluation results:\")\n",
    "for key, value in dev_results.items():\n",
    "  if isinstance(value, float):\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "  else:\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95f8c969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set evaluation results:\n",
      "  eval_loss: 0.6720\n",
      "  eval_model_preparation_time: 0.0024\n",
      "  eval_accuracy: 0.6200\n",
      "  eval_precision: 0.6200\n",
      "  eval_recall: 1.0000\n",
      "  eval_f1: 0.7654\n",
      "  eval_runtime: 3.7050\n",
      "  eval_samples_per_second: 13.4950\n",
      "  eval_steps_per_second: 0.5400\n"
     ]
    }
   ],
   "source": [
    "test_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    eval_dataset=tokenized_test.select(range(config[\"test_subset_size\"]))\n",
    ")\n",
    "\n",
    "test_results = test_trainer.evaluate()\n",
    "print(\"\\nTest set evaluation results:\")\n",
    "for key, value in test_results.items():\n",
    "  if isinstance(value, float):\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "  else:\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275a4e5e",
   "metadata": {},
   "source": [
    "This part is the test set performance of DistillBERT without fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "250341a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/cs681-final-sa-test/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base (non-fine-tuned) model test results:\n",
      "  eval_loss: 0.6950\n",
      "  eval_model_preparation_time: 0.0025\n",
      "  eval_accuracy: 0.4200\n",
      "  eval_precision: 0.6667\n",
      "  eval_recall: 0.1290\n",
      "  eval_f1: 0.2162\n",
      "  eval_runtime: 7.9035\n",
      "  eval_samples_per_second: 6.3260\n",
      "  eval_steps_per_second: 0.2530\n"
     ]
    }
   ],
   "source": [
    "base_test_trainer = Trainer(\n",
    "    model=base_model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    eval_dataset=tokenized_test.select(range(config[\"test_subset_size\"]))\n",
    ")\n",
    "\n",
    "base_test_results = base_test_trainer.evaluate()\n",
    "print(\"\\nBase (non-fine-tuned) model test results:\")\n",
    "for key, value in base_test_results.items():\n",
    "  if isinstance(value, float):\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "  else:\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c73d8c",
   "metadata": {},
   "source": [
    "This part is the test set performance of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4431c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM model test results:\n",
      "  accuracy: 0.6000\n",
      "  precision: 0.6571\n",
      "  recall: 0.7419\n",
      "  f1: 0.6970\n"
     ]
    }
   ],
   "source": [
    "X_test_subset = [test_dataset['sentence'][i] for i in range(config[\"test_subset_size\"])]\n",
    "y_test_subset = [test_dataset['label'][i] for i in range(config[\"test_subset_size\"])]\n",
    "\n",
    "svm_predictions = svm_pipeline.predict(X_test_subset)\n",
    "\n",
    "svm_accuracy = accuracy_score(y_test_subset, svm_predictions)\n",
    "svm_precision, svm_recall, svm_f1, _ = precision_recall_fscore_support(\n",
    "    y_test_subset, svm_predictions, average='binary'\n",
    ")\n",
    "\n",
    "svm_test_results = {\n",
    "    'eval_accuracy': svm_accuracy,\n",
    "    'eval_precision': svm_precision,\n",
    "    'eval_recall': svm_recall,\n",
    "    'eval_f1': svm_f1,\n",
    "    'accuracy': svm_accuracy,\n",
    "    'precision': svm_precision, \n",
    "    'recall': svm_recall,\n",
    "    'f1': svm_f1\n",
    "}\n",
    "\n",
    "print(\"\\nSVM model test results:\")\n",
    "for key, value in svm_test_results.items():\n",
    "  if key.startswith('eval_'):\n",
    "    continue\n",
    "  if isinstance(value, float):\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "  else:\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7ae92f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance comparison (Test Set):\n",
      "Metric                         Fine-tuned      Base model      SVM            \n",
      "---------------------------------------------------------------------------\n",
      "eval_loss                      0.6720         0.6950         0.0000\n",
      "eval_model_preparation_time    0.0024         0.0025         0.0000\n",
      "eval_accuracy                  0.6200         0.4200         0.6000\n",
      "eval_precision                 0.6200         0.6667         0.6571\n",
      "eval_recall                    1.0000         0.1290         0.7419\n",
      "eval_f1                        0.7654         0.2162         0.6970\n",
      "eval_runtime                   3.7050         7.9035         0.0000\n",
      "eval_samples_per_second        13.4950         6.3260         0.0000\n",
      "eval_steps_per_second          0.5400         0.2530         0.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPerformance comparison (Test Set):\")\n",
    "print(f\"{'Metric':<30} {'Fine-tuned':<15} {'Base model':<15} {'SVM':<15}\")\n",
    "print(\"-\" * 75)\n",
    "for key in test_results:\n",
    "    if isinstance(test_results[key], float):\n",
    "        svm_value = svm_test_results.get(key, 0)\n",
    "        improvement_ft = test_results[key] - base_test_results[key]\n",
    "        improvement_svm = svm_value - base_test_results[key]\n",
    "        print(f\"{key:<30} {test_results[key]:.4f}{'':<8} {base_test_results[key]:.4f}{'':<8} {svm_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "129c74b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "fine_tuned_values = [test_results[f'eval_{m}'] for m in metrics]\n",
    "base_values = [base_test_results[f'eval_{m}'] for m in metrics]\n",
    "svm_values = [svm_test_results[f'eval_{m}'] for m in metrics]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "rects1 = ax.bar(x - width, fine_tuned_values, width, label='Fine-tuned')\n",
    "rects2 = ax.bar(x, base_values, width, label='Base model')\n",
    "rects3 = ax.bar(x + width, svm_values, width, label='SVM')\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Performance Comparison on Test Set')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([m.capitalize() for m in metrics])\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "def add_labels(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "add_labels(rects1)\n",
    "add_labels(rects2)\n",
    "add_labels(rects3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d0a1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment_with_model(text, model_to_use):\n",
    "    device = config[\"device\"]\n",
    "    \n",
    "    try:\n",
    "        # Tokenize input text\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", \n",
    "                           padding=config[\"tokenizer_padding\"], \n",
    "                           truncation=config[\"tokenizer_truncation\"], \n",
    "                           max_length=config[\"tokenizer_max_length\"])\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Run prediction\n",
    "        model_on_device = model_to_use.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model_on_device(**inputs)\n",
    "        \n",
    "        predictions = torch.argmax(outputs.logits, dim=-1).item()\n",
    "        return \"Positive\" if predictions == 1 else \"Negative\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error with {device.type}: {e}. Falling back to CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", \n",
    "                       padding=config[\"tokenizer_padding\"], \n",
    "                       truncation=config[\"tokenizer_truncation\"], \n",
    "                       max_length=config[\"tokenizer_max_length\"])\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        model_on_device = model_to_use.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model_on_device(**inputs)\n",
    "        \n",
    "        predictions = torch.argmax(outputs.logits, dim=-1).item()\n",
    "        return \"Positive\" if predictions == 1 else \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5aabb757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    return predict_sentiment_with_model(text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e238545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment_base(text):\n",
    "    return predict_sentiment_with_model(text, base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36c65c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment_svm(text):\n",
    "    prediction = svm_pipeline.predict([text])[0]\n",
    "    return \"Positive\" if prediction == 1 else \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfb0f4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing predictions across all models:\n",
      "Text                                                         Ground Truth    Fine-tuned      Base model      SVM            \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Bad                                                          Negative        Positive        Positive        Negative       \n",
      "Good                                                         Positive        Positive        Positive        Positive       \n",
      "I hate this                                                  Negative        Positive        Positive        Positive       \n",
      "I love this                                                  Positive        Positive        Negative        Positive       \n",
      "This movie was OK                                            Positive        Positive        Negative        Positive       \n",
      "This movie was fantastic                                     Positive        Positive        Negative        Positive       \n",
      "This movie was terrible                                      Negative        Positive        Negative        Positive       \n",
      "This is not bad                                              Positive        Positive        Negative        Negative       \n",
      "Good movie but bad acting                                    Positive        Positive        Negative        Negative       \n",
      "Despite the poor beginning, the ending was great             Positive        Positive        Negative        Positive       \n",
      "The plot was intricate and the characters were well develope... Positive        Positive        Negative        Positive       \n",
      "A masterpiece of modern cinema with stunning visuals         Positive        Positive        Negative        Positive       \n",
      "The director failed to engage the audience                   Negative        Positive        Negative        Negative       \n",
      "Not the best film I've seen, but still enjoyable             Positive        Positive        Negative        Negative       \n",
      "I wouldn't recommend this to anyone                          Negative        Positive        Positive        Positive       \n",
      "It wasn't as bad as the critics suggested                    Positive        Positive        Negative        Negative       \n",
      "Absolutely brilliant performances by the entire cast         Positive        Positive        Negative        Positive       \n",
      "A complete waste of time and money                           Negative        Positive        Negative        Positive       \n",
      "The special effects couldn't save the weak storyline         Negative        Positive        Negative        Negative       \n",
      "Despite its flaws, the film manages to be entertaining       Positive        Positive        Negative        Positive       \n",
      "It's so bad it's actually good                               Positive        Positive        Negative        Negative       \n",
      "The film offers nothing new to the genre                     Negative        Positive        Negative        Positive       \n",
      "While not perfect, it exceeded my expectations               Positive        Positive        Negative        Negative       \n",
      "The soundtrack was the only redeeming quality                Negative        Positive        Negative        Negative       \n",
      "\n",
      "Model agreement:\n",
      "Fine-tuned/Base agreement: 4/24 (16.7%)\n",
      "Fine-tuned/SVM agreement: 14/24 (58.3%)\n",
      "Base/SVM agreement: 12/24 (50.0%)\n",
      "\n",
      "Model accuracy on test examples:\n",
      "Fine-tuned model: 15/24 (62.5%)\n",
      "Base model: 7/24 (29.2%)\n",
      "SVM model: 13/24 (54.2%)\n",
      "Best performing model: Fine-tuned\n"
     ]
    }
   ],
   "source": [
    "test_examples = [\n",
    "    (\"Bad\", \"Negative\"),\n",
    "    (\"Good\", \"Positive\"),\n",
    "    (\"I hate this\", \"Negative\"),\n",
    "    (\"I love this\", \"Positive\"),\n",
    "    (\"This movie was OK\", \"Positive\"),\n",
    "    (\"This movie was fantastic\", \"Positive\"),\n",
    "    (\"This movie was terrible\", \"Negative\"),\n",
    "    (\"This is not bad\", \"Positive\"),\n",
    "    (\"Good movie but bad acting\", \"Positive\"),\n",
    "    (\"Despite the poor beginning, the ending was great\", \"Positive\"),\n",
    "    (\"The plot was intricate and the characters were well developed\", \"Positive\"),\n",
    "    (\"A masterpiece of modern cinema with stunning visuals\", \"Positive\"),    \n",
    "    (\"The director failed to engage the audience\", \"Negative\"),\n",
    "    (\"Not the best film I've seen, but still enjoyable\", \"Positive\"),\n",
    "    (\"I wouldn't recommend this to anyone\", \"Negative\"),\n",
    "    (\"It wasn't as bad as the critics suggested\", \"Positive\"),\n",
    "    (\"Absolutely brilliant performances by the entire cast\", \"Positive\"),\n",
    "    (\"A complete waste of time and money\", \"Negative\"),\n",
    "    (\"The special effects couldn't save the weak storyline\", \"Negative\"),\n",
    "    (\"Despite its flaws, the film manages to be entertaining\", \"Positive\"),\n",
    "    (\"It's so bad it's actually good\", \"Positive\"),\n",
    "    (\"The film offers nothing new to the genre\", \"Negative\"),\n",
    "    (\"While not perfect, it exceeded my expectations\", \"Positive\"),\n",
    "    (\"The soundtrack was the only redeeming quality\", \"Negative\")\n",
    "]\n",
    "\n",
    "print(\"\\nComparing predictions across all models:\")\n",
    "print(f\"{'Text':<60} {'Ground Truth':<15} {'Fine-tuned':<15} {'Base model':<15} {'SVM':<15}\")\n",
    "print(\"-\" * 120)\n",
    "\n",
    "matches_ft_base = 0\n",
    "matches_ft_svm = 0\n",
    "matches_base_svm = 0\n",
    "fine_tuned_correct = 0\n",
    "base_correct = 0\n",
    "svm_correct = 0\n",
    "\n",
    "for example, ground_truth in test_examples:\n",
    "    fine_tuned_pred = predict_sentiment(example)\n",
    "    base_pred = predict_sentiment_base(example)\n",
    "    svm_pred = predict_sentiment_svm(example)\n",
    "    \n",
    "    if fine_tuned_pred == base_pred:\n",
    "        matches_ft_base += 1\n",
    "    if fine_tuned_pred == svm_pred:\n",
    "        matches_ft_svm += 1\n",
    "    if base_pred == svm_pred:\n",
    "        matches_base_svm += 1\n",
    "    \n",
    "    if ground_truth in [\"Positive\", \"Negative\"]:\n",
    "        if fine_tuned_pred == ground_truth:\n",
    "            fine_tuned_correct += 1\n",
    "        if base_pred == ground_truth:\n",
    "            base_correct += 1\n",
    "        if svm_pred == ground_truth:\n",
    "            svm_correct += 1\n",
    "    \n",
    "    display_text = example[:60] + \"...\" if len(example) > 60 else example\n",
    "    print(f\"{display_text:<60} {ground_truth:<15} {fine_tuned_pred:<15} {base_pred:<15} {svm_pred:<15}\")\n",
    "\n",
    "binary_examples = sum(1 for _, label in test_examples if label in [\"Positive\", \"Negative\"])\n",
    "fine_tuned_acc = (fine_tuned_correct / binary_examples) * 100 if binary_examples > 0 else 0\n",
    "base_acc = (base_correct / binary_examples) * 100 if binary_examples > 0 else 0\n",
    "svm_acc = (svm_correct / binary_examples) * 100 if binary_examples > 0 else 0\n",
    "\n",
    "ft_base_agreement = (matches_ft_base / len(test_examples)) * 100\n",
    "ft_svm_agreement = (matches_ft_svm / len(test_examples)) * 100\n",
    "base_svm_agreement = (matches_base_svm / len(test_examples)) * 100\n",
    "\n",
    "models = [\n",
    "    (\"Fine-tuned\", fine_tuned_acc),\n",
    "    (\"Base\", base_acc),\n",
    "    (\"SVM\", svm_acc)\n",
    "]\n",
    "best_model = max(models, key=lambda x: x[1])[0]\n",
    "\n",
    "print(f\"\\nModel agreement:\")\n",
    "print(f\"Fine-tuned/Base agreement: {matches_ft_base}/{len(test_examples)} ({ft_base_agreement:.1f}%)\")\n",
    "print(f\"Fine-tuned/SVM agreement: {matches_ft_svm}/{len(test_examples)} ({ft_svm_agreement:.1f}%)\")\n",
    "print(f\"Base/SVM agreement: {matches_base_svm}/{len(test_examples)} ({base_svm_agreement:.1f}%)\")\n",
    "\n",
    "print(f\"\\nModel accuracy on test examples:\")\n",
    "print(f\"Fine-tuned model: {fine_tuned_correct}/{binary_examples} ({fine_tuned_acc:.1f}%)\")\n",
    "print(f\"Base model: {base_correct}/{binary_examples} ({base_acc:.1f}%)\")\n",
    "print(f\"SVM model: {svm_correct}/{binary_examples} ({svm_acc:.1f}%)\")\n",
    "print(f\"Best performing model: {best_model}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs681-final-sa-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
